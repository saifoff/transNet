{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NEf2IR_pVKuP","executionInfo":{"status":"ok","timestamp":1700451504200,"user_tz":-360,"elapsed":25825,"user":{"displayName":"Dane Wick","userId":"03127177229231403423"}},"outputId":"c34380e5-73ef-4033-d3d8-f951018092c8"},"id":"NEf2IR_pVKuP","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/transliteration"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZMoyx6AvVNIZ","executionInfo":{"status":"ok","timestamp":1700451504201,"user_tz":-360,"elapsed":6,"user":{"displayName":"Dane Wick","userId":"03127177229231403423"}},"outputId":"ad87af4c-cdc2-434f-f7e2-d420ece02ef7"},"id":"ZMoyx6AvVNIZ","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/transliteration\n"]}]},{"cell_type":"code","execution_count":null,"id":"59ce0ad1-e992-4860-a2ad-c9c00909f17b","metadata":{"id":"59ce0ad1-e992-4860-a2ad-c9c00909f17b","outputId":"feeeb3ad-b464-4c13-e326-09ee27614d90","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700465595832,"user_tz":-360,"elapsed":3689,"user":{"displayName":"Dane Wick","userId":"03127177229231403423"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.97\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","      bangla       0.97      0.97      0.97      3983\n","     english       0.96      0.99      0.97      3375\n","       hindi       0.98      0.97      0.98      3437\n","       tamil       1.00      0.95      0.97      2300\n","\n","    accuracy                           0.97     13095\n","   macro avg       0.98      0.97      0.97     13095\n","weighted avg       0.97      0.97      0.97     13095\n","\n","\n","Confusion Matrix:\n","[[3861   68   50    4]\n"," [  15 3358    2    0]\n"," [  41   47 3345    4]\n"," [  54   42   23 2181]]\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Load your CSV file\n","file_path = 'tranliteration.csv'  # Replace with the actual file path\n","df = pd.read_csv(file_path)\n","\n","# Split the data into training and testing sets\n","train_data, test_data, train_labels, test_labels = train_test_split(\n","    df['text'], df['label'], test_size=0.2, random_state=42\n",")\n","\n","# TF-IDF Vectorization\n","tfidf_vectorizer = TfidfVectorizer()\n","train_vectors = tfidf_vectorizer.fit_transform(train_data)\n","test_vectors = tfidf_vectorizer.transform(test_data)\n","\n","# Train a Multinomial Naive Bayes classifier\n","classifier = MultinomialNB()\n","classifier.fit(train_vectors, train_labels)\n","\n","# Make predictions on the test set\n","predictions = classifier.predict(test_vectors)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(test_labels, predictions)\n","print(f'Accuracy: {accuracy:.2f}')\n","\n","print('\\nClassification Report:')\n","print(classification_report(test_labels, predictions))\n","\n","print('\\nConfusion Matrix:')\n","print(confusion_matrix(test_labels, predictions))\n"]},{"cell_type":"code","execution_count":null,"id":"153673f6-d5cc-4452-94d6-e545517b64f2","metadata":{"id":"153673f6-d5cc-4452-94d6-e545517b64f2","outputId":"3231b2a1-7e37-427b-c700-dbc49486bd67","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700465871512,"user_tz":-360,"elapsed":35853,"user":{"displayName":"Dane Wick","userId":"03127177229231403423"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.97\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","      bangla       0.93      0.99      0.96      3983\n","     english       0.99      0.98      0.99      3375\n","       hindi       0.99      0.95      0.97      3437\n","       tamil       0.99      0.94      0.96      2300\n","\n","    accuracy                           0.97     13095\n","   macro avg       0.97      0.97      0.97     13095\n","weighted avg       0.97      0.97      0.97     13095\n","\n","\n","Confusion Matrix:\n","[[3946   13   17    7]\n"," [  38 3323   10    4]\n"," [ 137   17 3274    9]\n"," [ 125    9   14 2152]]\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Load your dataset\n","file_path = 'tranliteration.csv'\n","data = pd.read_csv(file_path)\n","\n","# Split the data into training and testing sets\n","train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n","\n","# Extract features using CountVectorizer\n","vectorizer = CountVectorizer()\n","X_train = vectorizer.fit_transform(train_data['text'])\n","X_test = vectorizer.transform(test_data['text'])\n","\n","# Define the target variable\n","y_train = train_data['label']\n","y_test = test_data['label']\n","\n","# Initialize and train the model (Logistic Regression in this case)\n","model = LogisticRegression(max_iter=1000)\n","model.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","predictions = model.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, predictions)\n","classification_report_result = classification_report(y_test, predictions)\n","\n","# Print the results\n","print(f\"Accuracy: {accuracy:.2f}\\n\")\n","print(\"Classification Report:\\n\", classification_report_result)\n","\n","\n","print('\\nConfusion Matrix:')\n","print(confusion_matrix(test_labels, predictions))\n"]},{"cell_type":"code","execution_count":null,"id":"83ae3901-a30a-42b5-a07a-c7345cb04998","metadata":{"id":"83ae3901-a30a-42b5-a07a-c7345cb04998","outputId":"55268250-8c71-4976-b914-ba576ee50b91","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700465968992,"user_tz":-360,"elapsed":478,"user":{"displayName":"Dane Wick","userId":"03127177229231403423"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted class: ['hindi']\n"]}],"source":["# Assume 'new_input' is the text for which you want to make a prediction\n","new_input = [\"kya kam hai tumhara\"]\n","\n","# Transform the new input using the same vectorizer used during training\n","new_input_transformed = vectorizer.transform(new_input)\n","\n","# Make predictions using the trained model\n","predictions_new_input = model.predict(new_input_transformed)\n","\n","# Print the predictions\n","print(\"Predicted class:\", predictions_new_input)\n"]},{"cell_type":"code","execution_count":null,"id":"6bf69574-acce-4a6f-b449-2804c9847f93","metadata":{"id":"6bf69574-acce-4a6f-b449-2804c9847f93"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}